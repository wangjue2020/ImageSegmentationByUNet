{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AeE_RnZ_Pkda","outputId":"575bd30b-7ed9-4a9b-c6c2-39951d9b34a8","executionInfo":{"status":"ok","timestamp":1642237159173,"user_tz":-480,"elapsed":5589,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install torch\n","!pip3 install torchvision"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n","Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n"]}]},{"cell_type":"code","metadata":{"id":"muANAQ-IfEsO"},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import os\n","from torch.utils.data import Dataset\n","import cv2\n","from tqdm import tqdm\n","import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeyvrU0cDAwq","outputId":"4e873a47-038c-4a35-db09-172377ff89ee","executionInfo":{"status":"ok","timestamp":1642249361132,"user_tz":-480,"elapsed":18327,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Icq7DNNTAPKy","executionInfo":{"status":"ok","timestamp":1642249377384,"user_tz":-480,"elapsed":13978,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"outputId":"8f2de269-a718-407f-d70f-dd1918c7fc58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"0XNAba2ggOKa"},"source":["class UnetModel(nn.Module):\n","  def conv(self, in_channels, out_channels):\n","    block = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=(1,1)),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.Conv2d(out_channels, out_channels, kernel_size=3,padding=(1,1)),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU()\n","    )\n","    return block\n","  \n","  def up_conv(self, in_channels, out_channels):\n","    block = nn.Sequential(\n","        nn.Upsample(scale_factor=2),\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3,padding=(1,1)),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU()\n","    )\n","    return  block\n","  \n","  def __init__(self, in_channel, out_channel):\n","    super(UnetModel, self).__init__()\n","    \n","    self.conv1 = self.conv(in_channel,64)\n","    self.conv1_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv2 = self.conv(64, 128)\n","    self.conv2_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv3 = self.conv(128, 256)\n","    self.conv3_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv4 = self.conv(256, 512)\n","    self.conv4_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv5 = self.conv(512, 1024)\n","    \n","    self.up_conv4 = self.up_conv(1024, 512)\n","    self.up4_conv =self.conv(1024,512)\n","    self.up_conv3 = self.up_conv(512, 256)\n","    self.up3_conv = self.conv(512,256)\n","    self.up_conv2 = self.up_conv(256,128)\n","    self.up2_conv = self.conv(256,128)\n","    self.up_conv1 = self.up_conv(128,64)\n","    self.up1_conv = self.conv(128,64)\n","    \n","    self.conv_1x1 = nn.Conv2d(64,out_channel,kernel_size=1)\n","    self.sigmoid = nn.Sigmoid()\n","  def forward(self, x):\n","    out1 = self.conv1(x)\n","    \n","    out2 = self.conv1_maxpool(out1)\n","    out2 = self.conv2(out2)\n","    \n","    out3 = self.conv2_maxpool(out2)\n","    out3 = self.conv3(out3)\n","    \n","    out4 = self.conv3_maxpool(out3)\n","    out4 = self.conv4(out4)\n","    \n","    out5 = self.conv4_maxpool(out4)\n","    out5 = self.conv5(out5)\n","    \n","    exp5 = self.up_conv4(out5)\n","    exp5 = torch.cat((out4, exp5), dim=1)\n","    exp5 = self.up4_conv(exp5)\n","    \n","    exp4 = self.up_conv3(exp5)\n","    exp4 = torch.cat((out3, exp4), dim=1)\n","    exp4 = self.up3_conv(exp4)\n","    \n","    exp3 = self.up_conv2(exp4)\n","    exp3 = torch.cat((out2, exp3), dim=1)\n","    exp3 = self.up2_conv(exp3)\n","    \n","    exp2 = self.up_conv1(exp3)\n","    exp2 = torch.cat((out1, exp2), dim=1)\n","    exp2 = self.up1_conv(exp2)\n","    \n","    exp1 = self.conv_1x1(exp2)\n","    exp1 = self.sigmoid(exp1)\n","    return exp1\n","    \n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjFLD439-mZp"},"source":["class MyDataset(Dataset):\n","\n","    def __init__(self, len, home_directory, noise=2, mode=\"Train\"):\n","      self.len = len\n","      self.examples = []\n","      self.iter_index = 0\n","      self.X = torch.empty((len, 128,128))\n","      self.Y = torch.empty((len,128,128), dtype=torch.long)\n","      self.input_directory = os.path.join(home_directory, mode, 'input')\n","      self.mask_directory = os.path.join(home_directory, mode, 'mask')\n","      \n","      print(\"dataset input path {}\".format(self.input_directory))\n","      print(\"dataset mask path {}\".format(self.mask_directory))\n","      \n","      input_names = os.listdir(self.input_directory)\n","      input_names.sort()\n","      mask_names = os.listdir(self.mask_directory)\n","      mask_names.sort()\n","      \n","      self.set_dataset(self.input_directory, input_names, True)\n","      self.set_dataset(self.mask_directory, mask_names, False)\n","\n","      \n","    def set_dataset(self, directory, names, input_na = True):\n","      # print(self.len)\n","      # print(len(names))\n","      # print(names)\n","      index = 0\n","      for name in names:\n","        img_path = directory + '/' + name\n","        img = cv2.imread(img_path) \n","        \n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        img =img/255\n","        resize_img = cv2.resize(img, (128,128))\n","        if input_na:\n","          # print(index)\n","          self.X[index] = torch.tensor(resize_img)\n","        else:\n","          \n","          resize_img = torch.from_numpy(resize_img).float()\n","          self.Y[index] = resize_img\n","        index  += 1  \n","      \n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","        return (self.X[idx], self.Y[idx])\n","      \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GM2jVNFHM6RK","outputId":"865b0c92-f112-4b61-94b2-ed8474c4ad66","executionInfo":{"status":"ok","timestamp":1642250308879,"user_tz":-480,"elapsed":929279,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset_train = MyDataset(60,'/content/drive/My Drive/A3/cat_data/cat_data')\n","trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=20, shuffle=True)\n","\n","# dataset_test = MyDataset(20,'/content/drive/My Drive/A3/cat_data/cat_data', 'Test')\n","\n","model = UnetModel(1, 1)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.7)\n","\n","epochs = 10\n","model.train()\n","a = True\n","for e in range(epochs):\n","  running_loss = 0\n","  for images, labels in tqdm(trainloader):\n","    optimizer.zero_grad()\n","    images = images.unsqueeze(1)\n","    labels = labels.unsqueeze(1)\n","    labels = labels.float()\n","    log_ps = model(images)\n","    loss = criterion(log_ps, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    running_loss += loss.item()\n","  else:\n","    print(f\"Traning loss: {running_loss/len(trainloader)}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset input path /content/drive/My Drive/A3/cat_data/cat_data/Train/input\n","dataset mask path /content/drive/My Drive/A3/cat_data/cat_data/Train/mask\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:33<00:00, 31.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.4460305670897166\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:31<00:00, 30.36s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.613702396551768\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:30<00:00, 30.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.613702396551768\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:30<00:00, 30.18s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.6137023766835531\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:30<00:00, 30.03s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.613702396551768\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:30<00:00, 30.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.6137023766835531\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:29<00:00, 29.94s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.6137023766835531\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:29<00:00, 30.00s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.6137023766835531\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:29<00:00, 29.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.613702396551768\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [01:29<00:00, 30.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.613702396551768\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"UNboZq1_7QtB","outputId":"dfe48291-073d-4b3c-f772-3d54e8e62af7","executionInfo":{"status":"ok","timestamp":1642250931802,"user_tz":-480,"elapsed":11289,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset_test = MyDataset(21,'/content/drive/My Drive/A3/cat_data/cat_data', mode='Test')\n","testloader = torch.utils.data.DataLoader(dataset_test, batch_size=20, shuffle=True)\n","with torch.no_grad():\n","  for images, labels in tqdm(testloader):\n","      optimizer.zero_grad()\n","      images = images.unsqueeze(1)\n","      labels = labels.unsqueeze(1)\n","      log_ps = model(images)\n","      loss = criterion(log_ps, labels)\n","      running_loss += loss.item()\n","print(f\"Test loss: {running_loss/len(testloader)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset input path /content/drive/My Drive/A3/cat_data/cat_data/Test/input\n","dataset mask path /content/drive/My Drive/A3/cat_data/cat_data/Test/mask\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [00:10<00:00,  5.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Test loss: 2.2097961604595184\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}