{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transferLearning.ipynb","provenance":[],"authorship_tag":"ABX9TyO2zJRN7D+mn4UnRfqKt1y3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3jrIeYuVWxw","executionInfo":{"status":"ok","timestamp":1642730987771,"user_tz":-480,"elapsed":25506,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"outputId":"e6dad192-97f4-4f27-bd1f-3334e2c085ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import os\n","from torch.utils.data import Dataset\n","import cv2\n","from tqdm import tqdm\n","import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import random\n","import torchvision"],"metadata":{"id":"dqOClREnVebZ","executionInfo":{"status":"ok","timestamp":1642730994135,"user_tz":-480,"elapsed":6369,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wetciu7bVivq","executionInfo":{"status":"ok","timestamp":1642731018732,"user_tz":-480,"elapsed":24617,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}},"outputId":"ee2a4b15-044b-4e9f-9c6f-c71e712e1910"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","\n","    def __init__(self, len, home_directory, noise=2, mode=\"Train\",augment=False,other_dataset=False):\n","      self.augment = augment\n","      if self.augment:\n","        self.len = 3*len\n","      else:\n","        self.len = len\n","      self.examples = []\n","      self.iter_index = 0\n","      self.other=other_dataset\n","      self.X = torch.empty((self.len, 128,128))\n","      self.Y = torch.empty((self.len,128,128), dtype=torch.long)\n","      self.input_directory = os.path.join(home_directory, mode, 'input')\n","      self.mask_directory = os.path.join(home_directory, mode, 'mask')\n","      self.augmentation = augment\n","      print(\"dataset input path {}\".format(self.input_directory))\n","      print(\"dataset mask path {}\".format(self.mask_directory))\n","      print(self.len)\n","      # mask_names = os.listdir(self.mask_directory)\n","      # mask_names.sort()\n","      \n","      self.set_dataset()\n","      # self.set_dataset(self.mask_directory, mask_names, False)\n","\n","    def set_dataset(self):\n","      input_names = os.listdir(self.input_directory)\n","      input_names.sort()\n","      index = 0\n","      for name in input_names:\n","        img_path = self.input_directory+'/'+name\n","        if not self.other :\n","          mask_path =self.mask_directory+'/'+'mask_'+name\n","        else:\n","          mask_path =self.mask_directory+'/'+name\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        img = img/255\n","        resize_img = cv2.resize(img, (128,128))\n","\n","        mask = cv2.imread(mask_path)\n","        # print(mask.shape)\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n","        mask = mask/255\n","        resize_mask = cv2.resize(mask, (128,128))\n","\n","        self.X[self.iter_index] = torch.tensor(resize_img)\n","        resized_mask = torch.from_numpy(resize_mask).float()\n","        self.Y[self.iter_index] = resized_mask\n","        self.iter_index += 1\n","        if self.augment:\n","          self.data_augmentation(resize_img, resize_mask)\n","      \n","    def data_augmentation(self, image, mask):\n","      # image = torch.tensor(image).float()\n","      choices = [1,2,4]\n","      first = random.choice(choices)\n","      choices.remove(first)\n","      second = random.choice(choices)\n","      option = [first, second]\n","\n","      if 1 in option:\n","        newimg, newmask = self.randomHorizontalFlip(image, mask)\n","        self.X[self.iter_index] = newimg\n","        self.Y[self.iter_index] = newmask\n","        self.iter_index += 1\n","      if 2 in option:\n","        newimg, newmask = self.randomVerticalFlip(image, mask)\n","        self.X[self.iter_index] = newimg\n","        self.Y[self.iter_index] = newmask\n","        self.iter_index += 1\n","      if 3 in option: \n","        newimg, newmask = self.randZoom(image, mask)\n","        self.X[self.iter_index] = newimg\n","        self.Y[self.iter_index] = newmask\n","        self.iter_index += 1\n","      if 4 in option:\n","        newimg, newmask = self.randGaussianBlur(image, mask)\n","        self.X[self.iter_index] = newimg\n","        self.Y[self.iter_index] = newmask\n","        self.iter_index += 1\n","    \n","    def randomHorizontalFlip(self, image, mask):\n","      for i in range(image.shape[0]):\n","        flip_index = torch.arange(len(image[i])-1, -1, -1)\n","        image[i] = image[i][flip_index]\n","        mask_flip_index = torch.arange(len(mask[i])-1, -1, -1)\n","        mask[i] = mask[i][mask_flip_index]\n","      return torch.tensor(image), torch.from_numpy(mask).float()\n","    def randomVerticalFlip(self, img, mask):\n","      flip_index_v = torch.arange(len(img)-1,-1,-1)\n","      img = img[flip_index_v]\n","      mask_flip_index_v = torch.arange(len(mask)-1,-1,-1)\n","      mask = mask[mask_flip_index_v]\n","      return torch.tensor(img), torch.from_numpy(mask).float()\n","    \n","    def randZoom(self, image, mask):\n","      resize_coefficient = random.uniform(1,2)\n","      new_size = int(128*resize_coefficient)\n","      new_image = cv2.resize(image, (new_size, new_size))\n","      new_mask = cv2.resize(mask, (new_size, new_size))\n","      startx = random.randint(0, new_size-128)\n","      starty = random.randint(0, new_size-128)\n","      image = new_image[startx:startx+128, starty:starty+128]\n","      mask = new_mask[startx:startx+128, starty:starty+128]\n","      return torch.tensor(image), torch.from_numpy(mask).float()\n","    \n","    def randGaussianBlur(self, image, mask):\n","      image = cv2.GaussianBlur(image,(5,5),0)\n","      return torch.tensor(image), torch.from_numpy(mask).float()\n","\n","        \n","\n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","        return (self.X[idx], self.Y[idx])\n","      \n"],"metadata":{"id":"37UpAyNdlfgM","executionInfo":{"status":"ok","timestamp":1642731018732,"user_tz":-480,"elapsed":25,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class UnetModel(nn.Module):\n","  def conv(self, in_channels, out_channels):\n","    block = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=(1,1)),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.Conv2d(out_channels, out_channels, kernel_size=3,padding=(1,1)),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU()\n","    )\n","    return block\n","  \n","  def up_conv(self, in_channels, out_channels):\n","    block = nn.Sequential(\n","        nn.Upsample(scale_factor=2),\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3,padding=(1,1)),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU()\n","    )\n","    return  block\n","  \n","  def __init__(self, in_channel, out_channel):\n","    super(UnetModel, self).__init__()\n","    \n","    self.conv1 = self.conv(in_channel,64)\n","    self.conv1_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv2 = self.conv(64, 128)\n","    self.conv2_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv3 = self.conv(128, 256)\n","    self.conv3_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv4 = self.conv(256, 512)\n","    self.conv4_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.conv5 = self.conv(512, 1024)\n","    \n","    self.up_conv4 = self.up_conv(1024, 512)\n","    self.up4_conv =self.conv(1024,512)\n","    self.up_conv3 = self.up_conv(512, 256)\n","    self.up3_conv = self.conv(512,256)\n","    self.up_conv2 = self.up_conv(256,128)\n","    self.up2_conv = self.conv(256,128)\n","    self.up_conv1 = self.up_conv(128,64)\n","    self.up1_conv = self.conv(128,64)\n","    \n","    self.conv_1x1 = nn.Conv2d(64,out_channel,kernel_size=1)\n","    self.sigmoid = nn.Sigmoid()\n","  def forward(self, x):\n","    out1 = self.conv1(x)\n","    \n","    out2 = self.conv1_maxpool(out1)\n","    out2 = self.conv2(out2)\n","    \n","    out3 = self.conv2_maxpool(out2)\n","    out3 = self.conv3(out3)\n","    \n","    out4 = self.conv3_maxpool(out3)\n","    out4 = self.conv4(out4)\n","    \n","    out5 = self.conv4_maxpool(out4)\n","    out5 = self.conv5(out5)\n","    \n","    exp5 = self.up_conv4(out5)\n","    exp5 = torch.cat((out4, exp5), dim=1)\n","    exp5 = self.up4_conv(exp5)\n","    \n","    exp4 = self.up_conv3(exp5)\n","    exp4 = torch.cat((out3, exp4), dim=1)\n","    exp4 = self.up3_conv(exp4)\n","    \n","    exp3 = self.up_conv2(exp4)\n","    exp3 = torch.cat((out2, exp3), dim=1)\n","    exp3 = self.up2_conv(exp3)\n","    \n","    exp2 = self.up_conv1(exp3)\n","    exp2 = torch.cat((out1, exp2), dim=1)\n","    exp2 = self.up1_conv(exp2)\n","    \n","    exp1 = self.conv_1x1(exp2)\n","    exp1 = self.sigmoid(exp1)\n","    return exp1\n","    \n","    \n"],"metadata":{"id":"zqglSEgZY-Jp","executionInfo":{"status":"ok","timestamp":1642731018733,"user_tz":-480,"elapsed":23,"user":{"displayName":"Jue Wang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00979579278418875317"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dataset_train = MyDataset(301,'/content/drive/My Drive/A3/person', augment=False, other_dataset=True)\n","trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=20, shuffle=False)\n","\n","# dataset_test = MyDataset(20,'/content/drive/My Drive/A3/cat_data/cat_data', 'Test')\n","\n","model = UnetModel(1, 1)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.7)\n","\n","epochs = 30\n","model.train()\n","a = True\n","for e in range(epochs):\n","  running_loss = 0\n","  for images, labels in tqdm(trainloader):\n","    optimizer.zero_grad()\n","    images = images.unsqueeze(1)\n","    labels = labels.unsqueeze(1)\n","    labels = labels.float()\n","    log_ps = model(images)\n","    loss = criterion(log_ps, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    running_loss += loss.item()\n","  else:\n","    print(f\"Traning loss: {running_loss/len(trainloader)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAZcHEfCZDDv","outputId":"8f122a4d-1877-425a-cfd5-6659595b46f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset input path /content/drive/My Drive/A3/person/Train/input\n","dataset mask path /content/drive/My Drive/A3/person/Train/mask\n","301\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:55<00:00, 33.50s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.2721545221284032\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:47<00:00, 32.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.16573250200599432\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:58<00:00, 33.69s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.1466201520524919\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:53<00:00, 33.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.13419086951762438\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:47<00:00, 32.95s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.13100110366940498\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [09:00<00:00, 33.78s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.12037454638630152\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:58<00:00, 33.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.11638010898604989\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:51<00:00, 33.23s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.104615218937397\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [08:48<00:00, 33.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.10234654089435935\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [09:00<00:00, 33.81s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.09725007927045226\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [09:04<00:00, 34.02s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.08965142676606774\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [09:00<00:00, 33.80s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Traning loss: 0.08134133229032159\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 7/16 [04:10<05:22, 35.80s/it]"]}]},{"cell_type":"code","source":["dataset_train_origin = MyDataset(60,'/content/drive/My Drive/A3/cat_data/cat_data', augment=True)\n","trainloader_origin = torch.utils.data.DataLoader(dataset_train_origin, batch_size=20, shuffle=True)\n","\n","# dataset_test = MyDataset(20,'/content/drive/My Drive/A3/cat_data/cat_data', 'Test')\n","\n","# model = UnetModel(1, 1)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.7)\n","\n","epochs = 20\n","# model.train()\n","a = True\n","for e in range(epochs):\n","  running_loss = 0\n","  for images, labels in tqdm(trainloader_origin):\n","    optimizer.zero_grad()\n","    images = images.unsqueeze(1)\n","    labels = labels.unsqueeze(1)\n","    labels = labels.float()\n","    log_ps = model(images)\n","    loss = criterion(log_ps, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    running_loss += loss.item()\n","  else:\n","    print(f\"Traning loss: {running_loss/len(trainloader)}\")"],"metadata":{"id":"CLguqfG8gWs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_test = MyDataset(21,'/content/drive/My Drive/A3/cat_data/cat_data', mode='Test', augment=False)\n","testloader = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=True)\n","running_loss=0\n","with torch.no_grad():\n","  for images, labels in tqdm(testloader):\n","      optimizer.zero_grad()\n","      input = images.unsqueeze(1)\n","      labels = labels.unsqueeze(1)\n","      log_ps = model(input)\n","      i = log_ps.squeeze()\n","      l = labels.squeeze()\n","      print(i.shape)\n","      print(l.shape)\n","      final = images.squeeze()\n","      final = i*final\n","      \n","      plt.subplot(1, 3, 1)\n","      plt.imshow(i,cmap='gray')\n","      plt.subplot(1, 3, 2)\n","      plt.imshow(final,cmap='gray')\n","      plt.subplot(1, 3, 3)\n","      plt.imshow(l,cmap='gray')\n","      plt.show()\n","\n","      loss = criterion(log_ps, labels)\n","      running_loss += loss.item()\n","print(f\"Test loss: {running_loss/len(testloader)}\")"],"metadata":{"id":"81phE1v61H_G"},"execution_count":null,"outputs":[]}]}